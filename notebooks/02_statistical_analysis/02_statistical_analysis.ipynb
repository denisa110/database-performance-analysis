{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be401728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # 02 — Statistical Analysis of Query Performance\n",
    "# \n",
    "# Acest notebook rulează analize statistice inferențiale după etapa EDA:\n",
    "# \n",
    "# 1. **Încărcarea datelor** (aceleași CSV‑uri brute) și recrearea seturilor `merged_index` și `merged_shards`.\n",
    "# 2. **Teste de semnificație pereche**: *paired t‑test* și Wilcoxon.\n",
    "# 3. **Mărimea efectului**: Cohen’s *d*.\n",
    "# 4. **Intervale de încredere bootstrap 95 %** pentru Δ‑medie și %‑îmbunătățire.\n",
    "# 5. **Analiză de putere** pentru dimensiunea eșantionului necesar.\n",
    "# 6. **Salvare rezultate**: tabele CSV + grafic al bootstrap‑ului.\n",
    "# \n",
    "# ---\n",
    "# %%\n",
    "# 1️ Setup – imports & paths\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "from statsmodels.stats.power import TTestPower\n",
    "\n",
    "BASE_DIR = Path(\"D:/Disertatie/1.database_performance_analysis\").resolve()\n",
    "RAW_DIR  = BASE_DIR / \"data\" / \"raw\"\n",
    "TABLES_DIR = BASE_DIR / \"results\" / \"tables\"\n",
    "FIG_STAT_DIR = BASE_DIR / \"results\" / \"figures\" / \"statistical\"\n",
    "FIG_STAT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TABLES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RAW_FILES = {\n",
    "    \"no_index\"    : RAW_DIR / \"queries_no_index.csv\",\n",
    "    \"with_index\"  : RAW_DIR / \"queries_with_index.csv\",\n",
    "    \"no_shards\"   : RAW_DIR / \"queries_no_shards.csv\",\n",
    "    \"with_shards\" : RAW_DIR / \"queries_with_shards.csv\",\n",
    "}\n",
    "\n",
    "# %%\n",
    "# 2️ Load & merge datasets (same logic as EDA)\n",
    "idx    = pd.read_csv(RAW_FILES[\"with_index\"],   low_memory=False)\n",
    "no     = pd.read_csv(RAW_FILES[\"no_index\"],     low_memory=False)\n",
    "sh_idx = pd.read_csv(RAW_FILES[\"with_shards\"],  low_memory=False)\n",
    "sh_no  = pd.read_csv(RAW_FILES[\"no_shards\"],    low_memory=False)\n",
    "\n",
    "for df in [idx, no, sh_idx, sh_no]:\n",
    "    df[\"query_id\"] = df[\"query_id\"].astype(str)\n",
    "\n",
    "base_cols = [\"query_id\", \"documents_returned\"]\n",
    "\n",
    "idx2 = idx.rename(columns={\"execution_time_ms\": \"exec_time_index\"})\n",
    "no2  = no .rename(columns={\"execution_time_ms\": \"exec_time_no_index\"})\n",
    "merged_index = (\n",
    "    idx2[base_cols + [\"exec_time_index\"]]\n",
    "    .merge(no2[base_cols + [\"exec_time_no_index\"]], on=\"query_id\", how=\"inner\")\n",
    ")\n",
    "merged_index[\"diff_ms\"] = merged_index[\"exec_time_no_index\"] - merged_index[\"exec_time_index\"]\n",
    "merged_index[\"pct_impr\"] = merged_index[\"diff_ms\"] / merged_index[\"exec_time_no_index\"] * 100\n",
    "\n",
    "sh_idx2 = sh_idx.rename(columns={\"execution_time_ms\": \"exec_time_shards\"})\n",
    "sh_no2  = sh_no .rename(columns={\"execution_time_ms\": \"exec_time_no_shards\"})\n",
    "merged_shards = (\n",
    "    sh_idx2[base_cols + [\"exec_time_shards\"]]\n",
    "    .merge(sh_no2[base_cols + [\"exec_time_no_shards\"]], on=\"query_id\", how=\"inner\")\n",
    ")\n",
    "merged_shards[\"diff_ms\"] = merged_shards[\"exec_time_no_shards\"] - merged_shards[\"exec_time_shards\"]\n",
    "merged_shards[\"pct_impr\"] = merged_shards[\"diff_ms\"] / merged_shards[\"exec_time_no_shards\"] * 100\n",
    "\n",
    "# %%\n",
    "# Helper: run paired tests, effect size, bootstrap CI\n",
    "\n",
    "def paired_stats(df, col_before, col_after, label):\n",
    "    x = df[col_before]\n",
    "    y = df[col_after]\n",
    "    diff = x - y  # positive => before slower than after (improvement)\n",
    "\n",
    "    # Paired t‑test (H0: mean diff = 0)\n",
    "    t_stat, p_t = stats.ttest_rel(x, y)\n",
    "\n",
    "    # Wilcoxon signed‑rank\n",
    "    w_stat, p_w = stats.wilcoxon(x, y)\n",
    "\n",
    "    # Cohen's d (paired)\n",
    "    d = diff.mean() / diff.std(ddof=1)\n",
    "\n",
    "    # Bootstrap CI for mean diff & pct improvement\n",
    "    rng = np.random.default_rng(42)\n",
    "    boots = rng.choice(diff, size=(5000, len(diff)), replace=True).mean(axis=1)\n",
    "    ci_low, ci_high = np.percentile(boots, [2.5, 97.5])\n",
    "\n",
    "    # Power analysis (detect observed effect with alpha=0.05, power=0.8)\n",
    "    power_calc = TTestPower()\n",
    "    n_required = power_calc.solve_power(effect_size=abs(d), alpha=0.05, power=0.8, alternative='two-sided')\n",
    "\n",
    "    summary = {\n",
    "        \"group\": label,\n",
    "        \"n\": len(diff),\n",
    "        \"mean_before\": x.mean(),\n",
    "        \"mean_after\": y.mean(),\n",
    "        \"mean_diff\": diff.mean(),\n",
    "        \"cohen_d\": d,\n",
    "        \"t_stat\": t_stat, \"p_t\": p_t,\n",
    "        \"wilcoxon\": w_stat, \"p_w\": p_w,\n",
    "        \"ci_low\": ci_low, \"ci_high\": ci_high,\n",
    "        \"n_required_80p\": n_required,\n",
    "    }\n",
    "\n",
    "    # Save bootstrap distribution plot\n",
    "    plt.figure(figsize=(4,3))\n",
    "    plt.hist(boots, bins=40, density=True)\n",
    "    plt.axvline(ci_low, color='red', ls='--'); plt.axvline(ci_high, color='red', ls='--')\n",
    "    plt.title(f\"Bootstrap CI – {label}\")\n",
    "    plt.xlabel(\"Mean diff (ms)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIG_STAT_DIR / f\"bootstrap_{label}.png\")\n",
    "    plt.close()\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e74648bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    group    n  mean_before  mean_after  mean_diff  cohen_d  t_stat    p_t  \\\n",
      "0   index  122       66.131      65.311      0.820    0.031   0.344  0.732   \n",
      "1  shards  122       56.057      66.131    -10.074   -0.214  -2.360  0.020   \n",
      "\n",
      "   wilcoxon    p_w  ci_low  ci_high  n_required_80p  \n",
      "0    2972.5  0.477  -3.426    5.697        8106.119  \n",
      "1     349.0  0.000 -16.131   -0.549         173.837  \n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# 3️ Run analyses\n",
    "summary_index  = paired_stats(merged_index,  \"exec_time_no_index\",  \"exec_time_index\",  \"index\")\n",
    "summary_shards = paired_stats(merged_shards, \"exec_time_no_shards\", \"exec_time_shards\", \"shards\")\n",
    "\n",
    "summary_df = pd.DataFrame([summary_index, summary_shards])\n",
    "summary_df.to_csv(TABLES_DIR / \"statistical_summary.csv\", index=False)\n",
    "print(summary_df.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "174ba10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All statistical outputs saved:\n",
      "  • statistical_summary.csv\n",
      "  • diff_per_query_*.csv\n",
      "  • bootstrap_*.png (in figures/statistical)\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# 4️ Save per-query diff table for deep‑dive\n",
    "merged_index.to_csv(TABLES_DIR / \"diff_per_query_index.csv\", index=False)\n",
    "merged_shards.to_csv(TABLES_DIR / \"diff_per_query_shards.csv\", index=False)\n",
    "\n",
    "print(\"\\nAll statistical outputs saved:\\n\",\n",
    "      \" • statistical_summary.csv\\n\",\n",
    "      \" • diff_per_query_*.csv\\n\",\n",
    "      \" • bootstrap_*.png (in figures/statistical)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64e7b7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook finished \n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# 5️ Basic sanity check\n",
    "assert summary_df.shape[0] == 2, \"Expected two summary rows!\"\n",
    "print(\"Notebook finished \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
